{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmarAlsaqa/TextClassification/blob/master/Text_Classification_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjwDb5FVKc5r",
        "colab_type": "code",
        "outputId": "e1a7bdd9-56cb-438e-ebd1-e094355bb04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install torch<=1.2.0\n",
        "#!pip install torchtext\n",
        "!pip install torchtext==0.4\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: =1.2.0: No such file or directory\n",
            "Requirement already satisfied: torchtext==0.4 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.17.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m90KdQKKc53",
        "colab_type": "code",
        "outputId": "3526e4d1-1cf4-4836-f536-41b4a893b39b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.datasets import text_classification\n",
        "NGRAMS = 2\n",
        "import os\n",
        "if not os.path.isdir('./.data'):\n",
        "\tos.mkdir('./.data')\n",
        "train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n",
        "    root='./.data', ngrams=NGRAMS, vocab=None)\n",
        "BATCH_SIZE = 16\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120000lines [00:09, 13165.53lines/s]\n",
            "120000lines [00:18, 6541.99lines/s]\n",
            "7600lines [00:01, 6889.99lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjVYAIdHKc6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class TextSentiment(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "        \n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKZy__TgKc6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
        "EMBED_DIM = 32\n",
        "NUN_CLASS = len(train_dataset.get_labels())\n",
        "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpvZtKxbKc6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "    label = torch.tensor([entry[0] for entry in batch])\n",
        "    text = [entry[1] for entry in batch]\n",
        "    offsets = [0] + [len(entry) for entry in text]\n",
        "\n",
        "    \n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text = torch.cat(text)\n",
        "    return text, offsets, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PG4mKVAKc6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch)\n",
        "    for i, (text, offsets, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        output = model(text, offsets)\n",
        "        loss = criterion(output, cls)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "    \n",
        "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
        "\n",
        "def test(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "    for text, offsets, cls in data:\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text, offsets)\n",
        "            loss = criterion(output, cls)\n",
        "            loss += loss.item()\n",
        "            acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    return loss / len(data_), acc / len(data_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3KVqArsKc6n",
        "colab_type": "code",
        "outputId": "b0a13738-186d-4d53-fbdd-143252ff6039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "\n",
        "import time\n",
        "from torch.utils.data.dataset import random_split\n",
        "N_EPOCHS = 5\n",
        "min_valid_loss = float('inf')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "\n",
        "train_len = int(len(train_dataset) * 0.95)\n",
        "sub_train_, sub_valid_ = \\\n",
        "    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(sub_train_)\n",
        "    valid_loss, valid_acc = test(sub_valid_)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 28 seconds\n",
            "\tLoss: 0.0262(train)\t|\tAcc: 84.8%(train)\n",
            "\tLoss: 0.0001(valid)\t|\tAcc: 89.3%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 28 seconds\n",
            "\tLoss: 0.0118(train)\t|\tAcc: 93.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 90.8%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 28 seconds\n",
            "\tLoss: 0.0069(train)\t|\tAcc: 96.4%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 90.4%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 28 seconds\n",
            "\tLoss: 0.0038(train)\t|\tAcc: 98.1%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 90.7%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 28 seconds\n",
            "\tLoss: 0.0022(train)\t|\tAcc: 99.0%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 91.0%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOlty_E1Kc6w",
        "colab_type": "code",
        "outputId": "eccb8082-5114-49ef-ccb8-5a3cbb14df2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print('Checking the results of test dataset...')\n",
        "test_loss, test_acc = test(test_dataset)\n",
        "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset...\n",
            "\tLoss: 0.0002(test)\t|\tAcc: 90.7%(test)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvH69S7sKc64",
        "colab_type": "code",
        "outputId": "baefa8b0-86d7-4103-9e2e-d30d3dce2118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import re\n",
        "from torchtext.data.utils import ngrams_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "ag_news_label = {1 : \"World\",\n",
        "                 2 : \"Sports\",\n",
        "                 3 : \"Business\",\n",
        "                 4 : \"Sci/Tec\"}\n",
        "\n",
        "def predict(text, model, vocab, ngrams):\n",
        "    tokenizer = get_tokenizer(\"basic_english\")\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor([vocab[token]\n",
        "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "ex_text_str = \"Lift-off went smoothly, with the Atlas V rocket soaring from Florida just before sunrise and heading for the International Space Station, where it is due to arrive tomorrow.But just half an hour into its journey, Boeing reported that the capsule's insertion into orbit was not normal.Flight controllers are understood to be considering their options and insist the capsule is in a stable orbit.Inside, is a test dummy named Rosie, which is sitting in the commander's seat.Rosie has been dressed in a red polka-dot bandana and a royal blue spacesuit. It is named after the bicep-flexing riveter on Second World War posters.\"\n",
        "#ex_text_str = \"The church, built on the spot where Jesus is believed to have been born, was at imminent risk of collapse six years ago but has now been saved and is safe for generations to come.It is very sensitive and it was great to work here, project manager Afif Tweme says as he guides me around the building.\"\n",
        "#ex_text_str = \"Arteta left his post as Manchester City assistant manager, working under Pep Guardiola, last week to succeed Unai Emery as Arsen\"\n",
        "#ex_text_str = \"Non-political posts went up in the normal way. Was this Conservative censorship? To test that theory, Mr See ran an experiment.Don't vote for Jeremy Corbyn, he posted. Then: Make sure you vote.Neither post was published. Perhaps, he thought, it wasnt the content of the posts that was the problem, but the word vote.\"\n",
        "vocab = train_dataset.get_vocab()\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a Sci/Tec news\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "065lz1JsV3EO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}